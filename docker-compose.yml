# Default to GPU-enabled runtime when NVIDIA toolkit is available.

services:
  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
      network: host
    gpus: all
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - PATH=/opt/conda/bin:/data/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-all}
      - SQLITE_PATH=/data/personalcodex.db
      - MODELS_DIR=/data/models
      - STANDARD_WORKS_DB=/data/scripdb/standardworks.db
    volumes:
      - ./backend:/app
      - ./volumes:/data
    working_dir: /app
    command: bash -lc "uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"
    ports:
      - "8000:8000"

  ingest:
    build:
      context: ./infra/ingest-gpu
      dockerfile: Dockerfile
      network: host
    gpus: all
    env_file:
      - .env
    environment:
      - PATH=/opt/conda/bin:/data/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      - MOVE_PROCESSED=1
      - OCR_ENGINE=${OCR_ENGINE:-openai}
      - TROCR_MODEL_ID=${TROCR_MODEL_ID:-microsoft/trocr-large-handwritten}
      - OPENAI_OCR_MODEL=${OPENAI_OCR_MODEL:-gpt-4o-mini}
      - OPENAI_OCR_FALLBACK_MODEL=${OPENAI_OCR_FALLBACK_MODEL:-gpt-4o-mini}
      - OPENAI_OCR_DELAY_S=3.0
      - HF_HOME=/data/models
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-all}
      - NEWDATA_DIR=/data/newdata
      - IMAGES_DIR=/data/images
      - TXT_DIR=/data/txt
      - NOTES_DB=/data/notesdb/notes.db
      - STANDARD_WORKS_DB=/data/scripdb/standardworks.db
      - OPENAI_API_KEY_FILE=/run/secrets/openai.key
    volumes:
      - ./volumes:/data
      - ./volumes/openai.key:/run/secrets/openai.key:ro
    working_dir: /
    entrypoint: ["/bin/sh", "-lc"]
    command: "newdata-ingest"
    restart: "no"

  embeddings:
    build:
      context: ./infra/embeddings
      dockerfile: Dockerfile
      network: host
    gpus: all
    env_file:
      - .env
    environment:
      - PATH=/opt/conda/bin:/data/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      - HF_HOME=/data/models
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-all}
      - NOTES_DB=/data/notesdb/notes.db
      - EMBEDDING_MODEL_NAME=${EMBEDDING_MODEL_NAME:-sentence-transformers/all-MiniLM-L12-v2}
      - EMBEDDING_MODEL_DISTANCE=${EMBEDDING_MODEL_DISTANCE:-cosine}
      - EMBEDDING_BATCH_SIZE=${EMBEDDING_BATCH_SIZE:-32}
      - EMBEDDING_NORMALIZE=${EMBEDDING_NORMALIZE:-0}
    volumes:
      - ./volumes:/data
    working_dir: /
    entrypoint: ["/bin/sh", "-lc"]
    command: "notesdb-embeddings"
    restart: "no"

  scheduler:
    build:
      context: ./infra/embeddings
      dockerfile: Dockerfile
      network: host
    gpus: all
    env_file:
      - .env
    environment:
      - PATH=/data/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      - HF_HOME=/data/models
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-all}
      - NOTES_DB=/data/notesdb/notes.db
      - EMBEDDING_MODEL_NAME=${EMBEDDING_MODEL_NAME:-sentence-transformers/all-MiniLM-L12-v2}
      - EMBEDDING_MODEL_DISTANCE=${EMBEDDING_MODEL_DISTANCE:-cosine}
      - EMBEDDING_BATCH_SIZE=${EMBEDDING_BATCH_SIZE:-32}
      - EMBEDDING_NORMALIZE=${EMBEDDING_NORMALIZE:-0}
      - EMBEDDINGS_CRON=${EMBEDDINGS_CRON:-0 3 * * *}
      - EMBEDDINGS_COMMAND=${EMBEDDINGS_COMMAND:-notesdb-embeddings}
      - EMBEDDINGS_SCHEDULER_VERBOSE=${EMBEDDINGS_SCHEDULER_VERBOSE:-1}
    volumes:
      - ./volumes:/data
    working_dir: /
    entrypoint: ["/bin/sh", "-lc"]
    command: "notesdb-embeddings-scheduler"
    restart: unless-stopped
    depends_on:
      - embeddings

  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=development
      - CHOKIDAR_USEPOLLING=true
    volumes:
      - ./web:/usr/src/app
      - /usr/src/app/node_modules
    working_dir: /usr/src/app
    command: sh -c "npm install && npm run dev -- --host --port 3000"
    ports:
      - "3000:3000"
    depends_on:
      - api

  
