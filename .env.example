# Backend configuration
SQLITE_PATH=/data/personalcodex.db
STANDARD_WORKS_DB=/data/scripdb/standardworks.db
MODELS_DIR=/data/models

# Frontend configuration
# (add as needed)

# Ingestion / OCR / Layout
MOVE_PROCESSED=1
LAYOUT_ENGINE=heuristic  # heuristic | pymupdfllm | llm
# Heuristic thresholds
PARA_LINE_GAP=1.3
PARA_INDENT_PX=18
LEFT_EPSILON_PX=8
HEAD_SIZE_FACTOR=1.3

# Optional local LLM settings (not required)
LLM_MODE=off           # off | ollama | openai | vllm
LLM_MODEL=llama3.1:8b  # e.g., for ollama; or your model name
LLM_ENDPOINT=http://localhost:11434/v1  # ollama/OpenAI compatible endpoint
LLM_API_KEY=           # if using openai-compatible providers
OCR_ENGINE=doctr       # doctr | tesseract | paddle | auto
# If using OpenAI for OCR (ingest container default), set models:
OPENAI_OCR_MODEL=gpt-4o-mini
OPENAI_OCR_FALLBACK_MODEL=gpt-4o-mini
# TrOCR handwriting (Hugging Face) â€” set OCR_ENGINE=trocr to enable
TROCR_MODEL_ID=microsoft/trocr-large-handwritten
# Optional: point HF cache to /data/models for offline model files
HF_HOME=/data/models
TROCR_SEGMENT=page       # page | lines
TROCR_MAX_TOKENS=512
TROCR_LINE_HEIGHT=48
