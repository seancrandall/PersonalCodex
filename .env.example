# Backend configuration
SQLITE_PATH=/data/personalcodex.db
STANDARD_WORKS_DB=/data/scripdb/standardworks.db
MODELS_DIR=/data/models

# Frontend configuration
# (add as needed)

# Ingestion / OCR / Layout
MOVE_PROCESSED=1
LAYOUT_ENGINE=heuristic  # heuristic | pymupdfllm | llm
# Heuristic thresholds
PARA_LINE_GAP=1.3
PARA_INDENT_PX=18
LEFT_EPSILON_PX=8
HEAD_SIZE_FACTOR=1.3

# Optional local LLM settings (not required)
LLM_MODE=off           # off | ollama | openai | vllm
LLM_MODEL=llama3.1:8b  # e.g., for ollama; or your model name
LLM_ENDPOINT=http://localhost:11434/v1  # ollama/OpenAI compatible endpoint
LLM_API_KEY=           # if using openai-compatible providers
OCR_ENGINE=doctr       # doctr | tesseract | paddle | auto
# If using OpenAI for OCR (ingest container default), set models:
OPENAI_OCR_MODEL=gpt-4o-mini
OPENAI_OCR_FALLBACK_MODEL=gpt-4o-mini
# Throttle and backoff for OpenAI OCR to avoid rate limits
# Inter-page delay in seconds (jitter ±25% applied per page)
OPENAI_OCR_DELAY_S=3.0
# Exponential backoff settings for 429/5xx/408
OPENAI_OCR_MAX_RETRIES=5
OPENAI_OCR_BACKOFF_BASE_S=1.0
OPENAI_OCR_BACKOFF_CAP_S=30
# TrOCR handwriting (Hugging Face) — set OCR_ENGINE=trocr to enable
TROCR_MODEL_ID=microsoft/trocr-large-handwritten
# Optional: point HF cache to /data/models for offline model files
HF_HOME=/data/models
TROCR_SEGMENT=page       # page | lines
TROCR_MAX_TOKENS=512
TROCR_LINE_HEIGHT=48

# Embeddings generation
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L12-v2
EMBEDDING_MODEL_PATH=        # optional local path override
EMBEDDING_MODEL_DISTANCE=cosine
EMBEDDING_BATCH_SIZE=32
EMBEDDING_NORMALIZE=0        # set to 1 to store normalized vectors
EMBEDDINGS_CRON=0 3 * * *    # nightly at 03:00 server time
EMBEDDINGS_SCHEDULER_VERBOSE=1
