# Backend configuration
SQLITE_PATH=/data/personalcodex.db
STANDARD_WORKS_DB=/data/scripdb/standardworks.db
MODELS_DIR=/data/models

# Frontend configuration
# (add as needed)

# Ingestion / OCR / Layout
MOVE_PROCESSED=1
LAYOUT_ENGINE=heuristic  # heuristic | pymupdfllm | llm
# Heuristic thresholds
PARA_LINE_GAP=1.3
PARA_INDENT_PX=18
LEFT_EPSILON_PX=8
HEAD_SIZE_FACTOR=1.3

# Optional local LLM settings (not required)
LLM_MODE=off           # off | ollama | openai | vllm
LLM_MODEL=llama3.1:8b  # e.g., for ollama; or your model name
LLM_ENDPOINT=http://localhost:11434/v1  # ollama/OpenAI compatible endpoint
LLM_API_KEY=           # if using openai-compatible providers
