#!/usr/bin/env python
from __future__ import annotations

import argparse
import json
import os
import subprocess
from pathlib import Path
from typing import List, Dict, Any, Tuple


def run_tesseract_tsv(img: Path, lang: str, psm: int, oem: int) -> str:
    cmd = [
        "tesseract",
        str(img),
        "stdout",
        "-l",
        lang,
        "--oem",
        str(oem),
        "--psm",
        str(psm),
        "tsv",
    ]
    res = subprocess.run(cmd, check=True, capture_output=True)
    return res.stdout.decode("utf-8", errors="ignore")


def parse_tsv_to_blocks(tsv: str) -> List[Dict[str, Any]]:
    import csv
    from io import StringIO

    reader = csv.DictReader(StringIO(tsv), delimiter="\t")
    lines: Dict[str, Dict[str, Any]] = {}
    for row in reader:
        level = row.get("level")
        if not level:
            continue
        # We aggregate at line level (level==4)
        if row.get("level") not in {"4", "5"}:  # line or word
            continue
        line_key = (row.get("page_num", "1"), row.get("block_num", "0"), row.get("par_num", "0"), row.get("line_num", "0"))
        key = ":".join(line_key)
        try:
            left = int(row.get("left", "0"))
            top = int(row.get("top", "0"))
            width = int(row.get("width", "0"))
            height = int(row.get("height", "0"))
            conf = float(row.get("conf", "-1"))
        except Exception:
            left = top = width = height = 0
            conf = -1.0
        text = row.get("text", "").strip()

        if key not in lines:
            lines[key] = {
                "bbox": [left, top, left + width, top + height],
                "content": text if row.get("level") == "5" else "",
                "conf_sum": max(conf, 0.0),
                "conf_n": 1 if conf >= 0 else 0,
            }
        else:
            # expand bbox
            l = lines[key]
            l["bbox"][0] = min(l["bbox"][0], left)
            l["bbox"][1] = min(l["bbox"][1], top)
            l["bbox"][2] = max(l["bbox"][2], left + width)
            l["bbox"][3] = max(l["bbox"][3], top + height)
            if row.get("level") == "5" and text:
                l["content"] = (l["content"] + (" " if l["content"] else "") + text).strip()
            if conf >= 0:
                l["conf_sum"] += conf
                l["conf_n"] += 1

    blocks: List[Dict[str, Any]] = []
    # Sort by y then x
    def sort_key(item):
        b = item[1]
        return (b["bbox"][1], b["bbox"][0])

    for _, b in sorted(lines.items(), key=sort_key):
        content = b.get("content", "").strip()
        if not content:
            continue
        n = max(int(b.get("conf_n", 0)), 1)
        avg = float(b.get("conf_sum", 0.0)) / n
        blocks.append({
            "bbox": b["bbox"],
            "content": content,
            "block_type": "line",
            "confidence": avg,
        })
    return blocks


def process_path_with_tesseract(path: Path, lang: str, psm: int, oem: int) -> int:
    images: List[Path] = []
    if path.is_dir():
        images = sorted([p for p in path.iterdir() if p.suffix.lower() in {".png", ".jpg", ".jpeg", ".tif", ".tiff", ".bmp"}])
    else:
        images = [path]
    count = 0
    for img in images:
        try:
            tsv = run_tesseract_tsv(img, lang=lang, psm=psm, oem=oem)
        except subprocess.CalledProcessError as e:
            print(f"[ocr-image] tesseract failed on {img}: {e}")
            continue
        blocks = parse_tsv_to_blocks(tsv)
        # Write JSON and TXT next to image
        json_path = img.with_suffix(".ocr.json")
        txt_path = img.with_suffix(".txt")
        txt = "\n".join([b["content"] for b in blocks]) + "\n"
        json_path.write_text(json.dumps({"page": None, "blocks": blocks}, ensure_ascii=False, indent=2), encoding="utf-8")
        txt_path.write_text(txt, encoding="utf-8")
        print(f"[ocr-image] wrote {json_path.name} and {txt_path.name}")
        count += 1
    return count


def process_path_with_doctr(path: Path) -> int:
    try:
        from doctr.models import ocr_predictor  # type: ignore
        from PIL import Image
        import numpy as np
    except Exception as e:
        print(f"[ocr-image] doctr prerequisites missing ({e}); skipping doctr.")
        return 0
    predictor = ocr_predictor(pretrained=True)
    images: List[Path] = []
    if path.is_dir():
        images = sorted([p for p in path.iterdir() if p.suffix.lower() in {".png", ".jpg", ".jpeg", ".tif", ".tiff", ".bmp"}])
    else:
        images = [path]
    count = 0
    for img_path in images:
        try:
            img = Image.open(str(img_path)).convert("RGB")
        except Exception as e:
            print(f"[ocr-image] failed to open {img_path}: {e}")
            continue
        w, h = img.size
        try:
            doc = predictor([np.array(img)])
        except Exception as e:
            print(f"[ocr-image] doctr failed on {img_path}: {e}")
            continue
        try:
            export = doc.export()
        except Exception as e:
            print(f"[ocr-image] doctr export failed on {img_path}: {e}")
            continue
        blocks: List[Dict[str, Any]] = []
        pages = export.get("pages", []) or []
        page0 = pages[0] if pages else {}
        for block in page0.get("blocks", []) or []:
            for line in block.get("lines", []):
                words = line.get("words", [])
                texts = [w.get("value", "") for w in words if w.get("value")]
                if not texts:
                    continue
                xs: List[float] = []
                ys: List[float] = []
                confs: List[float] = []
                for wdict in words:
                    geom = wdict.get("geometry") or []
                    if geom and len(geom) == 2:
                        (x0, y0), (x1, y1) = geom
                        xs.extend([x0 * w, x1 * w])
                        ys.extend([y0 * h, y1 * h])
                    c = wdict.get("confidence")
                    if c is not None:
                        try:
                            confs.append(float(c))
                        except Exception:
                            pass
                if not xs or not ys:
                    continue
                bbox = [float(min(xs)), float(min(ys)), float(max(xs)), float(max(ys))]
                avg_conf = float(sum(confs) / len(confs)) if confs else None
                blocks.append({
                    "bbox": bbox,
                    "content": " ".join(texts).strip(),
                    "block_type": "line",
                    "confidence": avg_conf,
                })
        json_path = img_path.with_suffix(".ocr.json")
        txt_path = img_path.with_suffix(".txt")
        txt = "\n".join([b["content"] for b in blocks if b.get("content")]) + "\n"
        json_path.write_text(json.dumps({"page": None, "blocks": blocks}, ensure_ascii=False, indent=2), encoding="utf-8")
        txt_path.write_text(txt, encoding="utf-8")
        print(f"[ocr-image] wrote {json_path.name} and {txt_path.name} (doctr)")
        count += 1
    return count


def _segment_lines_opencv(img_bgr) -> List[Tuple[int, int, int, int]]:
    import cv2
    import numpy as np
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    # Binarize (adaptive helps uneven lighting)
    bin_img = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                    cv2.THRESH_BINARY_INV, 35, 15)
    # Merge text within the same line
    h, w = bin_img.shape
    ksize = max(15, w // 60)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (ksize, 3))
    morph = cv2.dilate(bin_img, kernel, iterations=1)
    # Find contours as line candidates
    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = []
    for c in contours:
        x, y, cw, ch = cv2.boundingRect(c)
        if ch < 10 or cw < 30:
            continue
        boxes.append((x, y, x + cw, y + ch))
    # Sort top-to-bottom
    boxes.sort(key=lambda b: (b[1], b[0]))
    # Merge overlapping boxes vertically (lines with split components)
    merged: List[Tuple[int, int, int, int]] = []
    for b in boxes:
        if not merged:
            merged.append(b)
            continue
        x0, y0, x1, y1 = merged[-1]
        a0, b0, a1, b1 = b
        # If current box overlaps significantly in y with last, merge
        if not (b0 > y1 or b1 < y0):
            nx0, ny0, nx1, ny1 = min(x0, a0), min(y0, b0), max(x1, a1), max(y1, b1)
            merged[-1] = (nx0, ny0, nx1, ny1)
        else:
            merged.append(b)
    return merged


def process_path_with_trocr(path: Path, model_id: str | None = None, device: str | None = None) -> int:
    try:
        from transformers import TrOCRProcessor, VisionEncoderDecoderModel
        import torch
        from PIL import Image
        import numpy as np
        import cv2
        import os as _os
    except Exception as e:
        print(f"[ocr-image] trocr prerequisites missing ({e}); skipping trocr.")
        return 0

    model_id = model_id or _os.environ.get("TROCR_MODEL_ID", "microsoft/trocr-large-handwritten")
    # Try to load from local cache first if HF_HOME provided
    local_only = False
    models_dir = _os.environ.get("HF_HOME") or _os.environ.get("MODELS_DIR")
    local_path = None
    if models_dir:
        nested = Path(models_dir) / model_id  # e.g., /data/models/microsoft/trocr-large-handwritten
        flat = Path(models_dir) / model_id.replace("/", "__")
        if nested.exists():
            local_only = True
            local_path = str(nested)
        elif flat.exists():
            local_only = True
            local_path = str(flat)

    try:
        processor = TrOCRProcessor.from_pretrained(local_path or model_id, local_files_only=local_only)
        model = VisionEncoderDecoderModel.from_pretrained(local_path or model_id, local_files_only=local_only)
    except Exception as e:
        print(f"[ocr-image] failed to load TrOCR model {model_id}: {e}")
        return 0

    device_t = torch.device("cuda" if (device or torch.cuda.is_available()) else "cpu")
    model = model.to(device_t)
    model.eval()

    images: List[Path] = []
    if path.is_dir():
        images = sorted([p for p in path.iterdir() if p.suffix.lower() in {".png", ".jpg", ".jpeg", ".tif", ".tiff", ".bmp"}])
    else:
        images = [path]
    count = 0
    for img_path in images:
        img_bgr = cv2.imread(str(img_path))
        if img_bgr is None:
            print(f"[ocr-image] failed to read image {img_path}")
            continue
        h, w = img_bgr.shape[:2]
        line_boxes = _segment_lines_opencv(img_bgr)
        blocks: List[Dict[str, Any]] = []
        for (x0, y0, x1, y1) in line_boxes:
            crop = img_bgr[max(0, y0):min(h, y1), max(0, x0):min(w, x1)]
            if crop.size == 0:
                continue
            pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
            try:
                inputs = processor(images=pil, return_tensors="pt").to(device_t)
                with torch.inference_mode():
                    generated = model.generate(**inputs, max_new_tokens=80)
                text = processor.batch_decode(generated, skip_special_tokens=True)[0]
            except Exception as e:
                print(f"[ocr-image] trocr inference failed on {img_path}: {e}")
                continue
            blocks.append({
                "bbox": [float(x0), float(y0), float(x1), float(y1)],
                "content": text.strip(),
                "block_type": "line",
                "confidence": None,
            })
        json_path = img_path.with_suffix(".ocr.json")
        txt_path = img_path.with_suffix(".txt")
        txt = "\n".join([b["content"] for b in blocks if b.get("content")]) + "\n"
        json_path.write_text(json.dumps({"page": None, "blocks": blocks}, ensure_ascii=False, indent=2), encoding="utf-8")
        txt_path.write_text(txt, encoding="utf-8")
        print(f"[ocr-image] wrote {json_path.name} and {txt_path.name} (trocr)")
        count += 1
    return count

def process_path_with_paddle(path: Path, lang: str) -> int:
    try:
        from paddleocr import PaddleOCR  # type: ignore
    except Exception as e:
        print(f"[ocr-image] paddleocr not available ({e}); skipping OCR.")
        return 0

    ocr = PaddleOCR(use_angle_cls=True, lang="en" if lang.startswith("en") else "en", show_log=False)  # basic EN; extend later
    images: List[Path] = []
    if path.is_dir():
        images = sorted([p for p in path.iterdir() if p.suffix.lower() in {".png", ".jpg", ".jpeg", ".tif", ".tiff", ".bmp"}])
    else:
        images = [path]
    count = 0
    for img in images:
        try:
            result = ocr.ocr(str(img), cls=True)
        except Exception as e:
            print(f"[ocr-image] paddleocr failed on {img}: {e}")
            continue
        blocks: List[Dict[str, Any]] = []
        # result is list for batch; we passed single path so result[0] is lines
        for line in (result[0] or []):
            box, (text, conf) = line
            xs = [pt[0] for pt in box]
            ys = [pt[1] for pt in box]
            bbox = [min(xs), min(ys), max(xs), max(ys)]
            blocks.append({
                "bbox": bbox,
                "content": (text or "").strip(),
                "block_type": "line",
                "confidence": float(conf) if conf is not None else None,
            })
        json_path = img.with_suffix(".ocr.json")
        txt_path = img.with_suffix(".txt")
        txt = "\n".join([b["content"] for b in blocks if b.get("content")]) + "\n"
        json_path.write_text(json.dumps({"page": None, "blocks": blocks}, ensure_ascii=False, indent=2), encoding="utf-8")
        txt_path.write_text(txt, encoding="utf-8")
        print(f"[ocr-image] wrote {json_path.name} and {txt_path.name} (paddle)")
        count += 1
    return count


def main() -> int:
    ap = argparse.ArgumentParser(description="OCR an image or directory of images (trocr → doctr → tesseract → paddle)")
    ap.add_argument("input", help="Image path or directory containing images")
    ap.add_argument("--engine", default=os.environ.get("OCR_ENGINE", "auto"), choices=["auto", "trocr", "doctr", "tesseract", "paddle"])  # auto tries trocr, doctr, tesseract, paddle
    ap.add_argument("--langs", default=os.environ.get("OCR_LANGS", "eng"))
    ap.add_argument("--psm", type=int, default=int(os.environ.get("TESSERACT_PSM", "3")))
    ap.add_argument("--oem", type=int, default=int(os.environ.get("TESSERACT_OEM", "1")))
    ap.add_argument("--dry-run", action="store_true")
    args = ap.parse_args()
    path = Path(args.input)
    print(f"[ocr-image] input={path} engine={args.engine} langs={args.langs} psm={args.psm} oem={args.oem}")
    if args.dry_run:
        print("[ocr-image] Dry run; not invoking OCR.")
        return 0
    if args.engine in ("auto", "trocr"):
        n = process_path_with_trocr(path)
        if args.engine == "trocr":
            return 0 if n >= 0 else 1
        if n > 0:
            return 0
    if args.engine in ("auto", "doctr"):
        n = process_path_with_doctr(path)
        if args.engine == "doctr":
            return 0 if n >= 0 else 1
        if n > 0:
            return 0
    if args.engine in ("auto", "tesseract"):
        try:
            return 0 if process_path_with_tesseract(path, args.langs, args.psm, args.oem) >= 0 else 1
        except FileNotFoundError:
            print("[ocr-image] tesseract not found")
        except Exception as e:
            print(f"[ocr-image] tesseract error: {e}")
        # If explicit tesseract, stop here
        if args.engine == "tesseract":
            return 2
    # paddle path (only if requested explicitly)
    if args.engine == "paddle":
        return 0 if process_path_with_paddle(path, args.langs) >= 0 else 1
    # engine=auto but no tesseract available, and we are avoiding heavy installs: skip gracefully
    print("[ocr-image] no OCR engine available in this environment; skipping.")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
